{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Mining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1hDk9hDvOH7",
        "outputId": "e972b264-d9a9-4162-82a6-c295e531cc6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "#NLTK-------------------------------\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "# Import libraries for feature \n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#Change current working directory to gdrive\n",
        "%cd /gdrive\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMwGQK7KAd7T",
        "outputId": "9f652491-9f1f-4dd5-f9a6-07d71cc841ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Read files\n",
        "textfile = r'/gdrive/My Drive/Textmining/Comments.csv'\n",
        "textData = pd.read_csv(textfile) #creates a dataframe\n",
        "\n",
        "CustInfofile = r'/gdrive/My Drive/Textmining/Customers.csv'\n",
        "CustInfoData = pd.read_csv(CustInfofile)  #creates a dataframe\n",
        "\n",
        "print(textData.shape)\n",
        "print(CustInfoData.shape)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 2)\n",
            "(2070, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWOTk6C1Ao45",
        "outputId": "60b4bd5e-cab0-4a87-cf79-2c50998bed93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Extract target column from Customer Info file\n",
        "y_train = CustInfoData[\"TARGET\"]\n",
        "X_train = CustInfoData.drop(columns=[\"TARGET\"]) #extracting training data without the target column\n",
        "                     \n",
        "print(X_train.shape)\n",
        "print(textData.shape)\n",
        "print(textData.head())\n",
        "print(y_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 16)\n",
            "(2070, 2)\n",
            "     ID                                           Comments\n",
            "0  1309  Does not like the way the phone works. It is t...\n",
            "1  3556  Wanted to know the nearest store location. Wan...\n",
            "2  2230  Wants to know how to do text messaging. Referr...\n",
            "3  2312  Asked how to disable call waiting. referred hi...\n",
            "4  3327  Needs help learning how to use the phone. I su...\n",
            "0       Cancelled\n",
            "1         Current\n",
            "2         Current\n",
            "3         Current\n",
            "4       Cancelled\n",
            "          ...    \n",
            "2065    Cancelled\n",
            "2066    Cancelled\n",
            "2067    Cancelled\n",
            "2068    Cancelled\n",
            "2069    Cancelled\n",
            "Name: TARGET, Length: 2070, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuWYNz2Ep17l"
      },
      "source": [
        "#Tokenize - Split the sentences to lists of words\n",
        "textData['CommentsTokenized'] = textData['Comments'].apply(word_tokenize)\n",
        "\n",
        "export_csv = textData.to_csv(r'/gdrive/My Drive/Textmining/TextDataTokenized_sou.csv')\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeYXLU-u_v9R"
      },
      "source": [
        "# Use English stemmer.\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "#Now do stemming - create a new dataframe to store stemmed version\n",
        "newTextData=pd.DataFrame()\n",
        "newTextData=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
        "newTextData['CommentsTokenizedStemmed'] = textData['CommentsTokenized'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
        "\n",
        "export_csv = newTextData.to_csv(r'/gdrive/My Drive/Textmining/snowball.csv')\n"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0ulptV7mKhl"
      },
      "source": [
        "stemmer1 = PorterStemmer()\n",
        "\n",
        "#Now do stemming - create a new dataframe to store stemmed version\n",
        "newTextData1=pd.DataFrame()\n",
        "newTextData1=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
        "newTextData1['CommentsTokenizedStemmed'] = textData['CommentsTokenized'].apply(lambda x: [stemmer1.stem(y) for y in x]) # Stem every word.\n",
        "\n",
        "export_csv = newTextData1.to_csv(r'/gdrive/My Drive/Textmining/porter.csv')"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M07E7VW7_y0d"
      },
      "source": [
        "\n",
        "#using snowball stemmer for further proceedings\n",
        "#Join stemmed strings\n",
        "newTextData['CommentsTokenizedStemmed'] = newTextData['CommentsTokenizedStemmed'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "export_csv = newTextData.to_csv(r'/gdrive/My Drive/Textmining/newTextData-Joined_sou.csv')"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiBguQloljam",
        "outputId": "942c8cdc-3a0e-497e-e38f-65ecbe6b0db6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Do Bag-Of-Words model - Term - Document Matrix\n",
        "#Learn the vocabulary dictionary and return term-document matrix.\n",
        "#count_vect = CountVectorizer(stop_words=None)\n",
        "count_vect = CountVectorizer(stop_words='english',lowercase=False)\n",
        "TD_counts = count_vect.fit_transform(newTextData.CommentsTokenizedStemmed)\n",
        "print(TD_counts.shape)\n",
        "print(TD_counts.dtype)\n",
        "print(count_vect.get_feature_names())\n",
        "#print(TD_counts)\n",
        "DF_TD_Counts=pd.DataFrame(TD_counts.toarray())\n",
        "print(DF_TD_Counts)\n",
        "export_csv = DF_TD_Counts.to_csv(r'/gdrive/My Drive/Textmining/TD_counts-TokenizedStemmed_sou.csv')\n"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 354)\n",
            "int64\n",
            "['3399', '3g', 'abysm', 'access', 'accessori', 'adapt', 'add', 'addit', 'additon', 'address', 'adit', 'adress', 'advertis', 'afraid', 'alway', 'angel', 'angri', 'ani', 'anoth', 'anyth', 'anytim', 'area', 'asap', 'ask', 'bad', 'basic', 'bateri', 'batteri', 'becaus', 'believ', 'better', 'bigger', 'book', 'bought', 'brain', 'bring', 'built', 'busi', 'button', 'buy', 'cancel', 'cancer', 'car', 'care', 'carrier', 'caus', 'cc', 'cell', 'certain', 'chang', 'charg', 'charger', 'check', 'chip', 'citi', 'claim', 'cleariti', 'cold', 'comapr', 'compani', 'compar', 'competit', 'complain', 'complaint', 'concept', 'connect', 'consisit', 'consist', 'constan', 'contact', 'continu', 'contract', 'correct', 'cost', 'coupl', 'cover', 'coverag', 'creat', 'credit', 'cstmer', 'cstmr', 'current', 'cust', 'custom', 'customr', 'date', 'day', 'dead', 'decent', 'defect', 'deo', 'did', 'die', 'differ', 'difficult', 'digiti', 'direct', 'disabl', 'doe', 'don', 'dont', 'drop', 'dure', 'easier', 'effect', 'encount', 'end', 'enemi', 'equip', 'everytim', 'everywher', 'evrey', 'exact', 'expect', 'expir', 'explain', 'facepl', 'fals', 'famili', 'featur', 'fed', 'figur', 'fine', 'fix', 'forev', 'forward', 'friend', 'function', 'furthermor', 'futur', 'gave', 'goat', 'good', 'great', 'gsm', 'handset', 'happi', 'hard', 'hate', 'hear', 'heard', 'help', 'higher', 'highway', 'hochi', 'hole', 'home', 'hope', 'horribl', 'hous', 'implement', 'improv', 'inadequ', 'includ', 'info', 'inform', 'ing', 'internet', 'intersect', 'issu', 'june', 'just', 'kid', 'kno', 'know', 'lame', 'later', 'lctn', 'learn', 'leroy', 'like', 'line', 'list', 'local', 'locat', 'locatn', 'long', 'los', 'lost', 'lot', 'love', 'major', 'make', 'manag', 'mani', 'manual', 'market', 'mean', 'messag', 'metropolitian', 'minut', 'misl', 'mistak', 'model', 'momma', 'mr', 'napeleon', 'near', 'nearest', 'need', 'network', 'new', 'news', 'notic', 'number', 'numer', 'offer', 'old', 'om', 'open', 'option', 'ori', 'ot', 'outbound', 'pass', 'pay', 'pda', 'peopl', 'perform', 'person', 'phone', 'piec', 'plan', 'pleas', 'point', 'polici', 'poor', 'possibl', 'probabl', 'problem', 'proper', 'provid', 'provis', 'purpos', 'rate', 'rater', 'realiz', 'realli', 'reason', 'receiv', 'recept', 'recption', 'reenter', 'refer', 'relat', 'rep', 'replac', 'respect', 'result', 'rid', 'right', 'ring', 'roam', 'roll', 'rubbish', 'rude', 'said', 'sale', 'say', 'screen', 'self', 'send', 'servic', 'shitti', 'shut', 'sign', 'signal', 'signific', 'simm', 'simpli', 'sinc', 'site', 'slow', 'sold', 'someon', 'sometim', 'soon', 'speak', 'speed', 'start', 'static', 'stole', 'store', 'stuff', 'stupid', 'substant', 'subtract', 'suck', 'suggest', 'supervisor', 'support', 'sure', 'surpris', 'suspect', 'suspend', 'switch', 'teach', 'technic', 'tell', 'terribl', 'test', 'text', 'think', 'thought', 'ticket', 'till', 'time', 'tire', 'today', 'toilet', 'told', 'tone', 'tower', 'transeff', 'transf', 'transfer', 'travel', 'tri', 'trust', 'turn', 'uncomfort', 'understand', 'unhappi', 'unlimit', 'unreli', 'unwil', 'upset', 'usag', 'use', 'useless', 'valu', 'veri', 'vm', 'wa', 'wait', 'want', 'wast', 'way', 'weak', 'web', 'websit', 'week', 'whi', 'wife', 'wish', 'wll', 'wold', 'work', 'wors', 'worst', 'wrong', 'xvyx', 'year', 'york']\n",
            "      0    1    2    3    4    5    6    ...  347  348  349  350  351  352  353\n",
            "0       0    0    0    0    0    0    0  ...    1    0    0    0    0    0    0\n",
            "1       0    0    0    0    1    0    0  ...    0    0    0    0    0    0    0\n",
            "2       0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "3       0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "4       0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "2065    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "2066    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "2067    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "2068    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "2069    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "\n",
            "[2070 rows x 354 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd8TZYnAxQbP",
        "outputId": "1162441b-9fee-427a-ddde-43d8bffdcf9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Compute TF-IDF Matrix\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(TD_counts)\n",
        "print(X_train_tfidf.shape)\n",
        "DF_TF_IDF=pd.DataFrame(X_train_tfidf.toarray())\n",
        "print(DF_TF_IDF)\n",
        "export_csv= DF_TF_IDF.to_csv(r'/gdrive/My Drive/Textmining/TFIDF_counts-TokenizedStemmed_sou.csv')\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 354)\n",
            "      0    1    2    3        4    5    ...  348  349  350  351  352  353\n",
            "0     0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1     0.0  0.0  0.0  0.0  0.27568  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2     0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3     0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4     0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "...   ...  ...  ...  ...      ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "2065  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2066  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2067  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2068  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2069  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "\n",
            "[2070 rows x 354 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBPt2ac8L_Eu",
        "outputId": "9ad9c2c2-03f9-44f8-b185-470a09d51adc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "combined=pd.concat([DF_TF_IDF,CustInfoData], axis=1)\n",
        "print(combined.shape)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 371)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD-yM19LM6OZ",
        "outputId": "d05a2f39-e18c-4160-97c4-6fb90c9d299b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Do one Hot encoding for categorical features\n",
        "X_cat = [\"Sex\",\"Status\",\"Car_Owner\",\"Paymethod\",\"LocalBilltype\",\"LongDistanceBilltype\"]\n",
        "#X_cat = combined.select_dtypes(exclude=['int','float64'])\n",
        "print(X_cat)\n",
        "combined_one_hot = pd.get_dummies(combined,columns=X_cat)\n",
        "print(combined_one_hot.shape)\n",
        "export_csv= combined_one_hot.to_csv(r'/gdrive/My Drive/Textmining/combined_one_hot_sou.csv')"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Sex', 'Status', 'Car_Owner', 'Paymethod', 'LocalBilltype', 'LongDistanceBilltype']\n",
            "(2070, 379)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dhGb14-NWSM",
        "outputId": "a841fb0a-7651-4f03-f21d-88d96dc95f79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Feature selection\n",
        "y = combined_one_hot[\"TARGET\"]\n",
        "x = combined_one_hot.drop(columns=[\"TARGET\"])\n",
        "combined_features= SelectKBest(score_func=chi2,k=40).fit_transform(x,y)\n",
        "print(combined_features.shape)\n",
        "\n",
        "combined_features =pd.DataFrame(combined_features)\n",
        "print(combined_features)\n",
        "\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 40)\n",
            "       0    1         2    3    4         5   ...   34   35   36   37   38   39\n",
            "0     0.0  0.0  0.000000  0.0  0.0  0.000000  ...  0.0  1.0  0.0  1.0  1.0  0.0\n",
            "1     0.0  0.0  0.000000  0.0  0.0  0.000000  ...  1.0  0.0  0.0  0.0  0.0  1.0\n",
            "2     0.0  0.0  0.000000  0.0  0.0  0.000000  ...  1.0  0.0  0.0  1.0  0.0  1.0\n",
            "3     0.0  0.0  0.000000  0.0  0.0  0.000000  ...  0.0  1.0  0.0  1.0  0.0  1.0\n",
            "4     0.0  0.0  0.000000  0.0  0.0  0.000000  ...  1.0  0.0  0.0  0.0  1.0  0.0\n",
            "...   ...  ...       ...  ...  ...       ...  ...  ...  ...  ...  ...  ...  ...\n",
            "2065  0.0  0.0  0.446161  0.0  0.0  0.460113  ...  0.0  1.0  0.0  1.0  0.0  1.0\n",
            "2066  0.0  0.0  0.000000  0.0  0.0  0.000000  ...  0.0  1.0  1.0  0.0  0.0  1.0\n",
            "2067  0.0  0.0  0.000000  0.0  0.0  0.000000  ...  1.0  0.0  0.0  0.0  0.0  1.0\n",
            "2068  0.0  0.0  0.000000  0.0  0.0  0.000000  ...  1.0  0.0  0.0  1.0  0.0  1.0\n",
            "2069  0.0  0.0  0.000000  0.0  0.0  0.000000  ...  0.0  1.0  0.0  1.0  0.0  1.0\n",
            "\n",
            "[2070 rows x 40 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geVCLka8xxjf",
        "outputId": "d2ea687d-5a9f-4462-ee9f-51bd13343576",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Construct a Random Forest Classifier on text data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "x_train,x_test,y_train,y_test=train_test_split(combined_features,y,test_size=0.2)\n",
        "\n",
        "clf=RandomForestClassifier()\n",
        "RF_text = clf.fit(x_train,y_train)\n",
        "\n",
        "rf_predictions = clf.predict(x_test)\n",
        "\n",
        "print(\"Accuracy score :\",accuracy_score(y_test, rf_predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, rf_predictions))\n"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score : 0.8671497584541062\n",
            "Confusion Matrix:\n",
            "[[126  29]\n",
            " [ 26 233]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.83      0.81      0.82       155\n",
            "     Current       0.89      0.90      0.89       259\n",
            "\n",
            "    accuracy                           0.87       414\n",
            "   macro avg       0.86      0.86      0.86       414\n",
            "weighted avg       0.87      0.87      0.87       414\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2q4tffpdT15",
        "outputId": "f1564ee9-d8dd-4cd8-9cc6-e33f4da6ee0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Do feature selection using a classification model\n",
        "#clf = ExtraTreesClassifier(n_estimators=50)\n",
        "clf = GradientBoostingClassifier(n_estimators=50)\n",
        "#clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(x_train,y_train)\n",
        "clf_predictions = clf.predict(x_test)\n",
        "\n",
        "print(\"Accuracy score :\",accuracy_score(y_test, clf_predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, clf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, clf_predictions))\n",
        "\n",
        "\n",
        "print(clf.feature_importances_)\n",
        "#model = SelectFromModel(clf, prefit=True)\n",
        "model = SelectFromModel(clf, prefit=True, max_features=7, threshold=-np.inf)\n",
        "#model = SelectFromModel(clf, prefit=True)\n",
        "X_new = model.transform(x_train)\n",
        "X_new_SelectedFeatures= pd.DataFrame(X_new)\n",
        "export_csv= X_new_SelectedFeatures.to_csv(r'/gdrive/My Drive/Textmining/X_new_SelectedFeatures_sou.csv')\n",
        "print(model.get_support())\n",
        "print(X_new_SelectedFeatures)\n",
        "#print(X_new_SelectedFeatures.shape)\n",
        "#print(X_new_SelectedFeatures.head())\n"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score : 0.8743961352657005\n",
            "Confusion Matrix:\n",
            "[[125  30]\n",
            " [ 22 237]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.85      0.81      0.83       155\n",
            "     Current       0.89      0.92      0.90       259\n",
            "\n",
            "    accuracy                           0.87       414\n",
            "   macro avg       0.87      0.86      0.86       414\n",
            "weighted avg       0.87      0.87      0.87       414\n",
            "\n",
            "[0.00000000e+00 0.00000000e+00 1.28036138e-03 6.52765131e-04\n",
            " 0.00000000e+00 0.00000000e+00 1.68837434e-03 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 1.29173806e-03 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 1.01772141e-03 0.00000000e+00\n",
            " 1.89364536e-03 0.00000000e+00 0.00000000e+00 1.97498101e-02\n",
            " 1.77646512e-01 2.04782851e-01 4.64813417e-02 1.17047956e-01\n",
            " 8.84903427e-02 8.15469429e-02 3.25648349e-02 3.61068472e-03\n",
            " 1.80248616e-02 2.18169771e-02 5.80271757e-02 6.70940252e-02\n",
            " 5.08136113e-02 1.56742577e-05 7.35461166e-04 3.72633245e-03]\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            "  True  True False  True  True  True False False False False  True  True\n",
            " False False False False]\n",
            "        0         1          2      3     4    5    6\n",
            "0     2.0  88427.00  13.860000  22.46  4.16  1.0  0.0\n",
            "1     0.0  93322.10  40.313333  29.92  0.00  0.0  1.0\n",
            "2     0.0   5185.31  62.053333  16.39  5.99  0.0  1.0\n",
            "3     0.0   2121.36  39.786667   2.02  0.00  0.0  1.0\n",
            "4     2.0  86695.40  13.906667  25.94  0.00  1.0  0.0\n",
            "...   ...       ...        ...    ...   ...  ...  ...\n",
            "1651  0.0  35000.00  23.000000  33.00  0.00  0.0  1.0\n",
            "1652  0.0  83891.90  61.020000  28.92  0.00  1.0  0.0\n",
            "1653  2.0  91861.00  41.980000  15.32  0.00  1.0  0.0\n",
            "1654  1.0  20550.90  22.120000  27.72  0.86  1.0  0.0\n",
            "1655  2.0  47639.10  43.000000  17.48  0.00  1.0  0.0\n",
            "\n",
            "[1656 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f08vQ1wRqtJ",
        "outputId": "6be8c4f3-f986-43dd-98f7-c2903734fa26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y = combined_one_hot[\"TARGET\"]\n",
        "x = combined_one_hot.drop(columns=[\"TARGET\"])\n",
        "combined_features1= SelectKBest(score_func=chi2,k=50).fit_transform(x,y)\n",
        "print(combined_features1.shape)\n",
        "\n",
        "combined_features1 =pd.DataFrame(combined_features1)\n",
        "print(combined_features1)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 50)\n",
            "            0    1    2    3         4         5   ...   44   45   46   47   48   49\n",
            "0     0.000000  0.0  0.0  0.0  0.000000  0.000000  ...  0.0  1.0  0.0  1.0  1.0  0.0\n",
            "1     0.000000  0.0  0.0  0.0  0.000000  0.000000  ...  1.0  0.0  0.0  0.0  0.0  1.0\n",
            "2     0.000000  0.0  0.0  0.0  0.000000  0.000000  ...  1.0  0.0  0.0  1.0  0.0  1.0\n",
            "3     0.000000  0.0  0.0  0.0  0.000000  0.000000  ...  0.0  1.0  0.0  1.0  0.0  1.0\n",
            "4     0.000000  0.0  0.0  0.0  0.000000  0.000000  ...  1.0  0.0  0.0  0.0  1.0  0.0\n",
            "...        ...  ...  ...  ...       ...       ...  ...  ...  ...  ...  ...  ...  ...\n",
            "2065  0.000000  0.0  0.0  0.0  0.000000  0.446161  ...  0.0  1.0  0.0  1.0  0.0  1.0\n",
            "2066  0.000000  0.0  0.0  0.0  0.000000  0.000000  ...  0.0  1.0  1.0  0.0  0.0  1.0\n",
            "2067  0.000000  0.0  0.0  0.0  0.000000  0.000000  ...  1.0  0.0  0.0  0.0  0.0  1.0\n",
            "2068  0.772949  0.0  0.0  0.0  0.545354  0.000000  ...  1.0  0.0  0.0  1.0  0.0  1.0\n",
            "2069  0.000000  0.0  0.0  0.0  0.000000  0.000000  ...  0.0  1.0  0.0  1.0  0.0  1.0\n",
            "\n",
            "[2070 rows x 50 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwnRkxtycT2G",
        "outputId": "b180f609-0d4c-4d5f-fb1f-9eb4a9af3621",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "x_train,x_test,y_train,y_test=train_test_split(combined_features1,y,test_size=0.2)\n",
        "\n",
        "clf=RandomForestClassifier()\n",
        "RF_text = clf.fit(x_train,y_train)\n",
        "\n",
        "rf_predictions = clf.predict(x_test)\n",
        "\n",
        "print(\"Accuracy score :\",accuracy_score(y_test, rf_predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, rf_predictions))\n"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score : 0.8623188405797102\n",
            "Confusion Matrix:\n",
            "[[124  30]\n",
            " [ 27 233]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.82      0.81      0.81       154\n",
            "     Current       0.89      0.90      0.89       260\n",
            "\n",
            "    accuracy                           0.86       414\n",
            "   macro avg       0.85      0.85      0.85       414\n",
            "weighted avg       0.86      0.86      0.86       414\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AbEQJDcfFHd",
        "outputId": "9482ff7a-ecc1-4cb0-e9b7-83044c3dbae3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Do feature selection using a classification model\n",
        "#clf = ExtraTreesClassifier(n_estimators=50)\n",
        "clf = GradientBoostingClassifier(n_estimators=50)\n",
        "#clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(x_train,y_train)\n",
        "clf_predictions = clf.predict(x_test)\n",
        "\n",
        "print(\"Accuracy score :\",accuracy_score(y_test, clf_predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, clf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, clf_predictions))\n",
        "\n",
        "\n",
        "print(clf.feature_importances_)\n",
        "#model = SelectFromModel(clf, prefit=True)\n",
        "model = SelectFromModel(clf, prefit=True, max_features=7, threshold=-np.inf)\n",
        "#model = SelectFromModel(clf, prefit=True)\n",
        "X_new = model.transform(x_train)\n",
        "X_new_SelectedFeatures= pd.DataFrame(X_new)\n",
        "export_csv= X_new_SelectedFeatures.to_csv(r'/gdrive/My Drive/Textmining/X_new_SelectedFeatures_sou.csv')\n",
        "print(model.get_support())\n",
        "print(X_new_SelectedFeatures)\n",
        "#print(X_new_SelectedFeatures.shape)\n",
        "#print(X_new_SelectedFeatures.head())\n"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score : 0.8405797101449275\n",
            "Confusion Matrix:\n",
            "[[124  30]\n",
            " [ 36 224]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.78      0.81      0.79       154\n",
            "     Current       0.88      0.86      0.87       260\n",
            "\n",
            "    accuracy                           0.84       414\n",
            "   macro avg       0.83      0.83      0.83       414\n",
            "weighted avg       0.84      0.84      0.84       414\n",
            "\n",
            "[0.00000000e+00 0.00000000e+00 4.92709038e-04 0.00000000e+00\n",
            " 3.78547102e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 7.78835919e-04 5.26286697e-04\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 1.85182889e-06 1.83580453e-03 0.00000000e+00 0.00000000e+00\n",
            " 6.50691515e-04 1.35030663e-03 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 1.27541739e-03 7.43087099e-04 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 1.48457314e-02 1.73984747e-01 2.03224963e-01\n",
            " 4.10967395e-02 1.40842860e-01 7.31135090e-02 6.37542245e-02\n",
            " 1.45552227e-02 4.44374695e-03 2.13693232e-02 2.89839827e-02\n",
            " 2.28106216e-02 1.21707254e-01 5.65857191e-02 1.78641469e-05\n",
            " 8.25845487e-03 2.37149843e-03]\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False  True  True\n",
            " False  True  True  True False False False False False  True  True False\n",
            " False False]\n",
            "        0        1          2      3     4    5    6\n",
            "0     0.0  85275.0  47.000000  22.48  0.00  1.0  1.0\n",
            "1     0.0  38538.4  12.326667  22.86  8.32  0.0  0.0\n",
            "2     0.0  92881.8  21.380000   2.15  6.12  0.0  0.0\n",
            "3     0.0  96681.0  19.760000   8.00  7.66  0.0  0.0\n",
            "4     1.0  82931.3  64.640000  19.24  0.00  0.0  1.0\n",
            "...   ...      ...        ...    ...   ...  ...  ...\n",
            "1651  1.0  28313.1  20.893333   6.89  0.00  0.0  0.0\n",
            "1652  2.0  17888.7  43.000000  29.41  0.00  0.0  0.0\n",
            "1653  2.0  20078.0  32.846667   9.65  0.00  0.0  0.0\n",
            "1654  2.0  47010.1  57.406667   2.54  0.00  0.0  0.0\n",
            "1655  2.0  76231.9  63.806667   2.01  0.00  1.0  1.0\n",
            "\n",
            "[1656 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ7tV0AgRtj3",
        "outputId": "d6b93707-44ea-41c2-906e-a5ad7b802ed4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y = combined_one_hot[\"TARGET\"]\n",
        "x = combined_one_hot.drop(columns=[\"TARGET\"])\n",
        "combined_features2= SelectKBest(score_func=chi2,k=60).fit_transform(x,y)\n",
        "print(combined_features2.shape)\n",
        "\n",
        "combined_features2 =pd.DataFrame(combined_features2)\n",
        "print(combined_features2)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 60)\n",
            "            0    1    2    3         4         5   ...   54   55   56   57   58   59\n",
            "0     0.000000  0.0  0.0  0.0  0.000000  0.000000  ...  0.0  1.0  0.0  1.0  1.0  0.0\n",
            "1     0.000000  0.0  0.0  0.0  0.000000  0.000000  ...  1.0  0.0  0.0  0.0  0.0  1.0\n",
            "2     0.000000  0.0  0.0  0.0  0.000000  0.000000  ...  1.0  0.0  0.0  1.0  0.0  1.0\n",
            "3     0.000000  0.0  0.0  0.0  0.000000  0.000000  ...  0.0  1.0  0.0  1.0  0.0  1.0\n",
            "4     0.000000  0.0  0.0  0.0  0.000000  0.000000  ...  1.0  0.0  0.0  0.0  1.0  0.0\n",
            "...        ...  ...  ...  ...       ...       ...  ...  ...  ...  ...  ...  ...  ...\n",
            "2065  0.000000  0.0  0.0  0.0  0.000000  0.446161  ...  0.0  1.0  0.0  1.0  0.0  1.0\n",
            "2066  0.000000  0.0  0.0  0.0  0.000000  0.000000  ...  0.0  1.0  1.0  0.0  0.0  1.0\n",
            "2067  0.000000  0.0  0.0  0.0  0.000000  0.000000  ...  1.0  0.0  0.0  0.0  0.0  1.0\n",
            "2068  0.772949  0.0  0.0  0.0  0.545354  0.000000  ...  1.0  0.0  0.0  1.0  0.0  1.0\n",
            "2069  0.000000  0.0  0.0  0.0  0.000000  0.000000  ...  0.0  1.0  0.0  1.0  0.0  1.0\n",
            "\n",
            "[2070 rows x 60 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHo0NDgIcdG8",
        "outputId": "bf032892-56a4-4aab-d3e0-a5efdc56d73b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "x_train,x_test,y_train,y_test=train_test_split(combined_features2,y,test_size=0.2)\n",
        "\n",
        "clf=RandomForestClassifier()\n",
        "RF_text = clf.fit(x_train,y_train)\n",
        "\n",
        "rf_predictions = clf.predict(x_test)\n",
        "\n",
        "print(\"Accuracy score :\",accuracy_score(y_test, rf_predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, rf_predictions))\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score : 0.8792270531400966\n",
            "Confusion Matrix:\n",
            "[[146  23]\n",
            " [ 27 218]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.84      0.86      0.85       169\n",
            "     Current       0.90      0.89      0.90       245\n",
            "\n",
            "    accuracy                           0.88       414\n",
            "   macro avg       0.87      0.88      0.88       414\n",
            "weighted avg       0.88      0.88      0.88       414\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7xNgybX8Khh",
        "outputId": "c4bd5a95-c438-4d3f-ed1e-72266d3cb928",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Do feature selection using a classification model\n",
        "#clf = ExtraTreesClassifier(n_estimators=50)\n",
        "clf = GradientBoostingClassifier(n_estimators=50)\n",
        "#clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(x_train,y_train)\n",
        "clf_predictions = clf.predict(x_test)\n",
        "\n",
        "print(\"Accuracy score :\",accuracy_score(y_test, clf_predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, clf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, clf_predictions))\n",
        "\n",
        "\n",
        "print(clf.feature_importances_)\n",
        "#model = SelectFromModel(clf, prefit=True)\n",
        "model = SelectFromModel(clf, prefit=True, max_features=7, threshold=-np.inf)\n",
        "#model = SelectFromModel(clf, prefit=True)\n",
        "X_new = model.transform(x_train)\n",
        "X_new_SelectedFeatures= pd.DataFrame(X_new)\n",
        "export_csv= X_new_SelectedFeatures.to_csv(r'/gdrive/My Drive/Textmining/X_new_SelectedFeatures_sou.csv')\n",
        "print(model.get_support())\n",
        "print(X_new_SelectedFeatures)\n",
        "#print(X_new_SelectedFeatures.shape)\n",
        "#print(X_new_SelectedFeatures.head())\n"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score : 0.855072463768116\n",
            "Confusion Matrix:\n",
            "[[133  36]\n",
            " [ 24 221]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.85      0.79      0.82       169\n",
            "     Current       0.86      0.90      0.88       245\n",
            "\n",
            "    accuracy                           0.86       414\n",
            "   macro avg       0.85      0.84      0.85       414\n",
            "weighted avg       0.85      0.86      0.85       414\n",
            "\n",
            "[0.         0.         0.         0.         0.00112204 0.\n",
            " 0.         0.00054626 0.         0.00060791 0.         0.\n",
            " 0.         0.         0.         0.         0.00063862 0.00035792\n",
            " 0.         0.         0.         0.         0.00229245 0.\n",
            " 0.         0.         0.         0.00196249 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.00049521\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.00027538 0.01704995 0.15553072 0.14983737 0.04452745 0.14341817\n",
            " 0.10249767 0.07999459 0.01890756 0.00037148 0.03405387 0.02969745\n",
            " 0.02255326 0.13043059 0.04582442 0.         0.0094113  0.00759589]\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False  True  True False  True\n",
            "  True  True False False False False False  True  True False False False]\n",
            "        0         1          2      3     4    5    6\n",
            "0     2.0  84948.00  29.446667  11.14  0.00  0.0  0.0\n",
            "1     1.0  71502.50  57.000000   0.00  0.00  0.0  0.0\n",
            "2     2.0  55860.00  14.573333  16.01  0.00  0.0  0.0\n",
            "3     0.0  78894.20  34.000000   2.00  1.41  0.0  0.0\n",
            "4     2.0     96.33  56.473333  26.13  0.00  1.0  0.0\n",
            "...   ...       ...        ...    ...   ...  ...  ...\n",
            "1651  2.0  14578.80  60.933333  11.91  0.00  1.0  1.0\n",
            "1652  2.0  28220.80  38.766667  26.49  0.00  0.0  0.0\n",
            "1653  1.0  92647.50  56.046667  16.04  5.74  1.0  0.0\n",
            "1654  1.0   8073.11  55.000000  28.70  0.00  0.0  1.0\n",
            "1655  2.0  81913.80  49.660000   6.70  0.00  0.0  0.0\n",
            "\n",
            "[1656 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMB33IG4yAgc",
        "outputId": "c924e2c0-39e5-4a35-edf1-10c67298233c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Sequential Forward Search\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "\n",
        "y = combined_one_hot[\"TARGET\"]\n",
        "x = combined_one_hot.drop(columns=[\"TARGET\"])\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "sfs1 = SFS(clf, \n",
        "           k_features=7, \n",
        "           forward=True, \n",
        "           floating=False, \n",
        "           verbose=2,\n",
        "           scoring='accuracy',\n",
        "           cv=0)\n",
        "\n",
        "sfs1 = sfs1.fit(x,y)\n",
        "sfs1.subsets_\n"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 378 out of 378 | elapsed:    1.9s finished\n",
            "\n",
            "[2020-10-31 04:10:47] Features: 1/7 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 377 out of 377 | elapsed:    3.3s finished\n",
            "\n",
            "[2020-10-31 04:10:50] Features: 2/7 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 376 out of 376 | elapsed:    3.3s finished\n",
            "\n",
            "[2020-10-31 04:10:53] Features: 3/7 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 375 out of 375 | elapsed:    3.5s finished\n",
            "\n",
            "[2020-10-31 04:10:57] Features: 4/7 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 374 out of 374 | elapsed:    3.4s finished\n",
            "\n",
            "[2020-10-31 04:11:00] Features: 5/7 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 373 out of 373 | elapsed:    3.5s finished\n",
            "\n",
            "[2020-10-31 04:11:04] Features: 6/7 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 372 out of 372 | elapsed:    3.7s finished\n",
            "\n",
            "[2020-10-31 04:11:07] Features: 7/7 -- score: 1.0"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: {'avg_score': 1.0,\n",
              "  'cv_scores': array([1.]),\n",
              "  'feature_idx': (354,),\n",
              "  'feature_names': ('ID',)},\n",
              " 2: {'avg_score': 1.0,\n",
              "  'cv_scores': array([1.]),\n",
              "  'feature_idx': (0, 354),\n",
              "  'feature_names': (0, 'ID')},\n",
              " 3: {'avg_score': 1.0,\n",
              "  'cv_scores': array([1.]),\n",
              "  'feature_idx': (0, 1, 354),\n",
              "  'feature_names': (0, 1, 'ID')},\n",
              " 4: {'avg_score': 1.0,\n",
              "  'cv_scores': array([1.]),\n",
              "  'feature_idx': (0, 1, 2, 354),\n",
              "  'feature_names': (0, 1, 2, 'ID')},\n",
              " 5: {'avg_score': 1.0,\n",
              "  'cv_scores': array([1.]),\n",
              "  'feature_idx': (0, 1, 2, 3, 354),\n",
              "  'feature_names': (0, 1, 2, 3, 'ID')},\n",
              " 6: {'avg_score': 1.0,\n",
              "  'cv_scores': array([1.]),\n",
              "  'feature_idx': (0, 1, 2, 3, 4, 354),\n",
              "  'feature_names': (0, 1, 2, 3, 4, 'ID')},\n",
              " 7: {'avg_score': 1.0,\n",
              "  'cv_scores': array([1.]),\n",
              "  'feature_idx': (0, 1, 2, 3, 4, 5, 354),\n",
              "  'feature_names': (0, 1, 2, 3, 4, 5, 'ID')}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsMRXOuv0Fi9",
        "outputId": "65cc8f4e-03fd-46d8-caaa-7e090c6e7ba4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Sequential forward search result\n",
        "print(sfs1.k_feature_names_)\n",
        "print(sfs1.k_score_)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 1, 2, 3, 4, 5, 'ID')\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QajekjwGiSjY",
        "outputId": "ad9cc811-5d39-4f67-bff0-b4be9ca98fb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "\n",
        "y = combined_one_hot[\"TARGET\"]\n",
        "x = combined_one_hot.drop(columns=[\"TARGET\"])\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "sfs2 = SFS(rf, \n",
        "           k_features=7, \n",
        "           forward=True, \n",
        "           floating=False, \n",
        "           verbose=2,\n",
        "           scoring='accuracy',\n",
        "           cv=0)\n",
        "\n",
        "sfs2 = sfs2.fit(x,y)\n",
        "sfs2.subsets_"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 378 out of 378 | elapsed:   54.8s finished\n",
            "\n",
            "[2020-10-31 04:13:18] Features: 1/7 -- score: 0.9995169082125603[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 377 out of 377 | elapsed:  2.4min finished\n",
            "\n",
            "[2020-10-31 04:15:41] Features: 2/7 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 376 out of 376 | elapsed:  2.4min finished\n",
            "\n",
            "[2020-10-31 04:18:04] Features: 3/7 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 375 out of 375 | elapsed:  2.4min finished\n",
            "\n",
            "[2020-10-31 04:20:29] Features: 4/7 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 374 out of 374 | elapsed:  2.4min finished\n",
            "\n",
            "[2020-10-31 04:22:54] Features: 5/7 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 373 out of 373 | elapsed:  2.3min finished\n",
            "\n",
            "[2020-10-31 04:25:15] Features: 6/7 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 372 out of 372 | elapsed:  2.4min finished\n",
            "\n",
            "[2020-10-31 04:27:37] Features: 7/7 -- score: 1.0"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: {'avg_score': 0.9995169082125603,\n",
              "  'cv_scores': array([0.99951691]),\n",
              "  'feature_idx': (354,),\n",
              "  'feature_names': ('ID',)},\n",
              " 2: {'avg_score': 1.0,\n",
              "  'cv_scores': array([1.]),\n",
              "  'feature_idx': (0, 354),\n",
              "  'feature_names': (0, 'ID')},\n",
              " 3: {'avg_score': 1.0,\n",
              "  'cv_scores': array([1.]),\n",
              "  'feature_idx': (0, 1, 354),\n",
              "  'feature_names': (0, 1, 'ID')},\n",
              " 4: {'avg_score': 1.0,\n",
              "  'cv_scores': array([1.]),\n",
              "  'feature_idx': (0, 1, 3, 354),\n",
              "  'feature_names': (0, 1, 3, 'ID')},\n",
              " 5: {'avg_score': 1.0,\n",
              "  'cv_scores': array([1.]),\n",
              "  'feature_idx': (0, 1, 3, 4, 354),\n",
              "  'feature_names': (0, 1, 3, 4, 'ID')},\n",
              " 6: {'avg_score': 1.0,\n",
              "  'cv_scores': array([1.]),\n",
              "  'feature_idx': (0, 1, 3, 4, 5, 354),\n",
              "  'feature_names': (0, 1, 3, 4, 5, 'ID')},\n",
              " 7: {'avg_score': 1.0,\n",
              "  'cv_scores': array([1.]),\n",
              "  'feature_idx': (0, 1, 2, 3, 4, 5, 354),\n",
              "  'feature_names': (0, 1, 2, 3, 4, 5, 'ID')}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7BwwsfIi0Og",
        "outputId": "4a06c2ed-920c-4e3f-c07e-24177146472a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "new_features= list(sfs2.k_feature_names_)\n",
        "x=combined_one_hot[new_features].values\n",
        "y= combined_one_hot[\"TARGET\"].values\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
        "\n",
        "clf=RandomForestClassifier()\n",
        "RF_text = clf.fit(x_train,y_train)\n",
        "\n",
        "rf_predictions = clf.predict(x_test)\n",
        "\n",
        "print(\"Accuracy score :\",accuracy_score(y_test, rf_predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, rf_predictions))\n",
        "\n",
        "clf1=DecisionTreeClassifier()\n",
        "DF_text = clf1.fit(x_train,y_train)\n",
        "\n",
        "df_predictions = clf1.predict(x_test)\n",
        "\n",
        "print(\"Accuracy score :\",accuracy_score(y_test, df_predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, df_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, df_predictions))\n",
        "\n"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score : 0.5797101449275363\n",
            "Confusion Matrix:\n",
            "[[ 63  84]\n",
            " [ 90 177]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.41      0.43      0.42       147\n",
            "     Current       0.68      0.66      0.67       267\n",
            "\n",
            "    accuracy                           0.58       414\n",
            "   macro avg       0.54      0.55      0.55       414\n",
            "weighted avg       0.58      0.58      0.58       414\n",
            "\n",
            "Accuracy score : 0.5700483091787439\n",
            "Confusion Matrix:\n",
            "[[ 63  84]\n",
            " [ 94 173]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.40      0.43      0.41       147\n",
            "     Current       0.67      0.65      0.66       267\n",
            "\n",
            "    accuracy                           0.57       414\n",
            "   macro avg       0.54      0.54      0.54       414\n",
            "weighted avg       0.58      0.57      0.57       414\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}